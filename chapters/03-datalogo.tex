\chapter{The \datalogo Language}
\label{chap:datalogo}

\remy{Define the semantics for \datalogo, 
 state the convergence theorems, 
 and give examples for each case.
 Then describe the semi-na\"ive algorithm.}

For fifty years, the relational data model has been the main choice for
representing, modeling, and processing data.  Its main query
language, SQL, is found today in a wide range of applications and
devices, from smart phones, to database servers, to distributed
cloud-based clusters.  The reason for its success is the {\em data
  independence principle}, which separates the declarative model from
the physical implementation~\cite{DBLP:journals/cacm/Codd70}, and
enables advanced implementation techniques, such as cost-based
optimizations, indices, materialized views, incremental view
maintenance, parallel evaluation, and many others, while keeping the
same simple, declarative interface to the data unchanged.

But scientists today often need to perform tasks that require
iteration over the data.
Gradient descent, clustering, page-rank, network centrality, inference
in knowledge graphs are some examples of common tasks in data science
that require iteration.  While SQL has introduced recursion since 1999
(through Common Table Expressions, CTE), it has many cumbersome
limitations and is little used in practice~\cite{frankmcsherry-2022}.

The need to support recursion in a declarative language led to the
development of Datalog in the mid 80s~\cite{DBLP:conf/pods/Vianu21}.
Datalog adds recursion to the relational query language, yet enjoys several elegant
properties: it has a simple, declarative semantics; its na\"ive
bottom-up evaluation algorithm always terminates; and it admits a few
powerful optimizations, such as semi-na\"ive evaluation and magic set
rewriting.  Datalog has been extensively studied in the literature;
see~\cite{DBLP:journals/ftdb/GreenHLZ13} for a survey
and~\cite{DBLP:books/mc/18/MaierTKW18,DBLP:conf/pods/Vianu21} for historical notes.

However, Datalog is not the answer to modern needs, because it only
supports monotone queries over sets.  Most tasks in data science today
require the interleaving of recursion and aggregate computation.
Aggregates are not monotone under set inclusion, and therefore they
are not supported by the framework of pure Datalog.  Neither SQL'99
nor popular open-source Datalog systems like
Souffl\'e~\cite{DBLP:conf/cav/JordanSS16} allow recursive queries to
have aggregates.  While several proposals have been made to extend
Datalog with
aggregation~\cite{DBLP:conf/pods/GangulyGZ91,DBLP:conf/pods/RossS92,DBLP:journals/jcss/GangulyGZ95,DBLP:journals/vldb/MazuranSZ13,DBLP:conf/icde/ShkapskyYZ15,DBLP:conf/sigmod/ShkapskyYICCZ16,DBLP:conf/amw/ZanioloYDI16,DBLP:journals/tplp/ZanioloYDSCI17,DBLP:conf/amw/ZanioloYIDSC18,DBLP:journals/tplp/CondieDISYZ18,DBLP:conf/sigmod/0001WMSYDZ19,DBLP:journals/corr/abs-1910-08888,DBLP:journals/corr/abs-1909-08249,DBLP:journals/debu/ZanioloD0LL021},
these extensions are at odds with the elegant properties of Datalog
and have not been adopted by either Datalog systems or SQL engines.

In this paper we propose a foundation for a query language that
supports both recursion and aggregation.  Our proposal is based on the
concept of $K$-relations, introduced in a seminal
paper by Green, Karvounarakis, and Tannen~\cite{DBLP:conf/pods/GreenKT07}.
In a $K$-relation, tuples are
mapped to a fixed semiring. Standard relations (sets) are
$\B$-relations where tuples are mapped to the Boolean semiring $\B$,
relations with duplicates (bags) are $\N$-relations, sparse tensors
are $\R$-relations, and so on.  Queries over $K$-relations are the
familiar relational queries, where the operations $\wedge, \vee$ are
replaced by the operations $\otimes, \oplus$ in the semiring;
importantly, an existential quantifier $\exists$ becomes an
$\oplus$-aggregate operator.
$K$-relations are a very powerful abstraction, because they open up
the possibility of adapting query processing and optimization
techniques to other domains~\cite{DBLP:conf/pods/KhamisNR16}.

Our first contribution is to introduce an extension of Datalog to
$K$-relations.  We call the language \datalogo 
 (pronounced ``Datalog-Oh''),
 where the superscript
$\circ$ represents a (semi)-ring. \datalogo has a declarative semantics
based on the least fixpoint, and supports both recursion and
aggregates.  We illustrate throughout this paper its utility through
several examples that are typical for recursive data processing.  In
order to define the least fixpoint semantics of \datalogo, the semiring
needs to be partially ordered.  For this purpose, we introduce an
algebraic structure called a {\em Partially Ordered Pre-Semiring (POPS)\/},
which generalizes the more familiar naturally ordered semirings.  This
generalization is necessary for some applications.  For example, the
bill-of-material program (Example~\ref{ex:sum1:sum2}) is naturally
expressed over the lifted reals, $\R_\bot$, which is a POPS that is
not naturally ordered.

Like Datalog, \datalogo can be evaluated using the {\em na\"ive algorithm},
by repeatedly applying all rules of the program, until there is no
more change.  However, unlike Datalog, a \datalogo program may diverge.
Our second contribution consists of a full characterization of the
POPS that guarantee that every \datalogo program terminates.  More
precisely, we show that termination is guaranteed iff the POPS enjoys
a certain algebraic property called {\em
  stability}~\cite{semiring_book}.  The result is based on an analysis
of the fixpoint of a vector-valued polynomial function over a semiring, which is of
independent interest.  With some abuse, we will say in this paper that
a \datalogo program {\em converges}, if the na\"ive algorithm terminates
in a finite number of steps; we do not consider ``convergence in the
limit'', for example in an $\omega$-continuous
semirings~\cite{DBLP:conf/pods/GreenKT07,DBLP:journals/jacm/EsparzaKL10}.

Finally, we describe how the {\em semi-na\"ive algorithm} can be
extended to \datalogo, under certain restrictions on the POPS.  This
should be viewed as an illustration of the potential for applying
advanced optimizations to \datalogo: in a companion
paper~\cite{DBLP:conf/sigmod/WangK0PS22}, we introduced a simple, yet
powerful optimization technique for \datalogo, and showed, among other
things, that magic set rewriting can be obtained using several
applications of that rule.

The remainder of this Chapter is organized as follows. 
We define POPS in Sec.~\ref{sec:pops} and give several examples.
In Sec.~\ref{sec:lfp} we consider the least fixpoint of monotone
functions over posets, and prove an upper bound on the number of
iterations needed to compute the least fixpoint.  We define \datalogo
formally in Sec.~\ref{sec:datalogo}, and give several examples.
The convergence results described in Theorem~\ref{th:main:intro} are
stated formally and proven in Sec.~\ref{sec:complexity}.
Sec.~\ref{sec:semi:naive} presents a generalization of semi-na\"ive
evaluation to \datalogo.  We discuss how \datalogo can express Datalog
queries with negation using 3-valued logic in
Sec.~\ref{sec:fitting}.  Finally, we conclude in
Sec.~\ref{sec:conclusions}.

\section{Partially Ordered Pre-Semirings (POPS)}
\label{sec:pops}

In this section, we review the basic algebraic notions of (pre-)semirings,
$P$-relations, and sum-product queries.
We also introduce an extension called partially ordered pre-semiring (POPS).

\subsection{(Pre-)Semirings and POPS}

\begin{defn}[(Pre-)semiring]
A {\em pre-semiring}~\cite{semiring_book} is a tuple
$\bm S = (S, \oplus, \otimes, 0, 1)$ where $\oplus$ and $\otimes$ are
binary operators on $S$ for which $(S, \oplus, 0)$ is a commutative
monoid, $(S, \otimes, 1)$ is a monoid, and $\otimes$ distributes over
$\oplus$.
When the {\em absorption rule} $x \otimes 0 = 0$ holds
for all $x \in S$, we call $\bm S$ a {\em semiring}.\footnote{Some
  references, e.g.~\cite{DBLP:journals/ai/KohlasW08}, define a
  semiring without absorption.}
%
When $\oplus$ is commutative, then we say that the
pre-semiring is {\em commutative}.  In this paper we only consider
commutative pre-semirings, and we will simply refer to them as
pre-semirings.
\end{defn}

In any (pre-)semiring $\bm S$, the relation $x \preceq_S y$ defined as
$\exists z: x \oplus z = y$, is a {\em preorder}, which means that it
is reflexive and transitive, but it is not anti-symmetric in general.
When $\preceq_S$ is anti-symmetric, then it is a partial order, and is
called the {\em natural order} on $\bm S$; in that case we say that
$\bm S$ is {\em naturally ordered}.

\begin{ex}
  Some simple examples of pre-semirings\remy{Fix on Arxiv.} are the Booleans
  $(\B \defeq \set{0,1}, \vee, \wedge, 0, 1)$, the natural numbers
  $(\N, +, \times , 0, 1)$, and the real numbers
  $(\R, +, \times, 0, 1)$.  We will refer to them simply as $\B, \N$
  and $\R$.  The natural order on $\B$ is $0 \preceq_\B 1$ (or {\sf
    false} $\preceq_\B$ {\sf true}); the natural order on $\N$ is the
  same as the familiar total order $\leq$ of numbers.  $\R$ is not
  naturally ordered, because $x \preceq_\R y$ holds for every
  $x,y \in \R$.  Another useful example is the {\em tropical semiring}
  $\trop^+ = (\R_+ \cup \{\infty\}, \min,+, \infty, 0)$, where the
  natural order $x \preceq y$ is the {\em reverse} order $x \geq y$ on
  $\R_+ \cup \{\infty\}$.
\end{ex}


A key idea we introduce in this paper is the decoupling of the partial order from the
algebraic structure of the (pre-)semiring.
The decoupling allows us to inject a partial order when the (pre-)semiring is not
naturally ordered, or when we need a {\em different} partial order than the natural order.

\begin{defn}[POPS] \label{def:pops} A {\em partially ordered pre-semiring} (POPS) is a tuple
  $\bm P = (P, \oplus, \otimes, 0, 1, \sqsubseteq)$, where
  $(P, \oplus, \otimes, 0, 1)$ is a pre-semiring, $(P, \sqsubseteq)$
  is a poset, and $\oplus, \otimes$ are {\em monotone}\footnote{Monotonicity means
  $x\sqsubseteq x'$ and $y \sqsubseteq y'$ imply $x\oplus y \sqsubseteq x' \oplus y'$
  and $x \otimes y \sqsubseteq x' \otimes y'$.}
  operators under $\sqsubseteq$.
  In this paper, we will assume that every poset $(P, \sqsubseteq)$ has a minimum
  element denoted by $\bot$.
\end{defn}

A POPS satisfies the identities $\bot \oplus \bot = \bot$ and
$\bot \otimes \bot = \bot$, because, by monotonicity and the fact that
$(P,\oplus,0)$ and $(P,\otimes,1)$ are commutative monoids, we have
$\bot \oplus \bot \sqsubseteq \bot \oplus 0 = \bot$, and
$\bot \otimes \bot \sqsubseteq \bot \otimes 1 = \bot$.  We say that
the multiplicative operator $\otimes$ is {\em strict} if the identity
$x \otimes \bot = \bot$ holds for every $x \in P$.

Throughout this paper we will assume that $\otimes$ is strict,
unless otherwise stated.
One of the reasons for insisting on the strictness assumption is that
we can ``extract'' from any POPS a semiring called the {\em core semiring}\remy{Remove?}
 of the POPS,
as shown in the following simple proposition.

\begin{prop} \label{prop:s:plus:bot} Given an arbitrary POPS
  $\bm P=(P,\oplus,\otimes,0,1,\sqsubseteq)$.  Define the subset
  $P\oplus \bot \defeq \setof{x\oplus\bot}{x \in P} \subseteq P$.
  Then, $(P\oplus \bot, \oplus, \otimes, 0\oplus \bot, 1 \oplus \bot)$
  is a semiring.  We denote this semiring by $\bm P \oplus \bot$, and
  refer to it as the {\em core} semiring of $\bm P$.
\end{prop}
%
\begin{proof}
  We use the fact that $\otimes$ is strict, and check that
  $\bm P\oplus\bot$ is closed under $\oplus$ and $\otimes$:
  $(x\oplus\bot)\oplus(y\oplus\bot)=(x\oplus
  y)\oplus(\bot\oplus\bot)=(x\oplus y)\oplus\bot$, and similarly
  $(x\oplus\bot)\otimes(y\oplus\bot)=(x\otimes y)\oplus (x\otimes\bot)
  \oplus (y\otimes \bot) \oplus\bot = (x\otimes
  y)\oplus\bot\oplus\bot\oplus\bot=(x\otimes y)\oplus\bot \in \bm P
  \oplus \bot$.  Finally, it suffices to observe that $\bot= 0\oplus\bot$ is the identity
  for $\oplus$ and $1\oplus\bot$ is the identity for $\otimes$.
\end{proof}

Every naturally ordered semiring is a POPS, where $\bot = 0$ and
$\otimes$ is strict, and its core is itself, $\bm S \oplus 0 = \bm S$.
The converse does not hold: some POPS are not naturally ordered; a
simple example of a non-naturally ordered POPS is the set of {\em lifted
  reals},
$\R_\bot \defeq (\R \cup \set{\bot}, +, *, 0, 1, \sqsubseteq)$, where
$x+\bot = x*\bot = \bot$ for all $x$, and $x \sqsubseteq y$ iff
$x = \bot$ or $x=y$.  Its core semiring is the trivial semiring
$\bm R_\bot + \bot = \set{\bot}$ consisting of a single element.  We
will consider similarly the lifted natural numbers, $\N_\bot$.

\subsection{Polynomials over POPS}
\label{subsec:polynomial}

\remy{Remove this section?}

Fix a POPS $\bm P = (P, \oplus, \otimes, 0, 1, \sqsubseteq)$.
We are interested in analysing behaviors of vector-valued multivariate functions on $P$
defined by composing $\oplus$ and $\otimes$.
These functions are multivariate polynomials.
Writing polynomials in $\bm P$ using the symbols $\oplus, \otimes$
is cumbersome and difficult to parse. Consequently, we replace them with $+, \cdot$ when the underlying
POPS $\bm P$ is clear from context; furthermore, we will also
abbreviate a multiplication $a\cdot b$ with $ab$.  As usual, $a^k$
denotes the product of $k$ copies of $a$, where $a^0 \defeq 1$.

Let $x_1, \ldots, x_N$ be $N$ variables.  A {\em monomial} (on $\bm P$) is an
expression of the form:
%
\begin{align}
  m \defeq & c \cdot x_1^{k_1}\cdot \cdots \cdot x_N^{k_N} \label{eq:def:monomial}
\end{align}
%
where $c \in P$ is some constant.  Its {\em degree} is
$\degree(m) \defeq k_1+\cdots+k_N$.  A (multivariate) {\em polynomial}
is a sum:
%
\begin{align}
  f(x_1, \ldots, x_N) \defeq & m_1 + m_2 + \cdots + m_q \label{eq:def:polynomial}
\end{align}
%
where each $m_i$ is a monomial.  The polynomial $f$ defines a function
$P^N \rightarrow P$ in the obvious way, and, with some abuse,
we will denote by $f$ both the polynomial and the function it defines.
Notice that $f$ is monotone in each of its arguments.

A {\em vector-valued polynomial function} on $\bm P$ is a function
$\bm f : P^N \rightarrow P^M$ whose component functions are polynomials.
In particular, the vector-valued polynomial function is a
{\em tuple of polynomials} $\bm f = (f_1, \ldots, f_M)$ where each $f_i$ is a
polynomial in variables $x_1, \ldots, x_N$.

We note a subtlety when dealing with POPS:
when the POPS is not a semiring, then we cannot ``remove'' monomials
by setting their coefficient $c=0$, because $0$ is not absorbing.
Instead, we must ensure that they are not included in the polynomial~\eqref{eq:def:polynomial}.
For example, consider the POPS of the lifted reals, $\bm R_\bot$, and
the linear polynomial $f(x) = ax + b$.  If we set $a = 0$, we do not
obtain the constant function $g(x)=b$, because
$f(\bot) = a\bot + b = \bot + b = \bot \neq g(\bot)=b$.  We just have
to be careful to not include monomials we don't want.

\subsection{\texorpdfstring{$P$-Relations}{P-Relations}}

\label{subsec:p:relations}

Fix a relational vocabulary, $\sigma = \set{R_1, \ldots, R_m}$, where
each $R_i$ is a relation name, with an associated arity.  Let $D$ be
an infinite domain of constants, for example the set of all strings
over a fixed alphabet, or the set of natural numbers.  Recall that an
instance of the relation $R_i$ is a finite subset of
$D^{\text{arity}(R_i)}$, or equivalently, a mapping
$D^{\text{arity}(R_i)} \rightarrow \B$ assigning $1$ to all tuples
present in the relation.  Following~\cite{DBLP:conf/pods/GreenKT07},
we generalize this abstraction from $\B$ to an arbitrary POPS $\bm P$.

Given a relation name $R_i \in \sigma$, a {\em ground atom} of $R_i$
is an expression of the form $R_i(\bm u)$, where
$\bm u \in D^{\arity(R_i)}$.  Let $\ground(R_i,D)$ denote the set of
all ground atoms of $R_i$, and
$\ground(\sigma, D) \defeq \bigcup_i \ground(R_i,D)$ denote the set of
all ground atoms over the entire vocabulary $\sigma$.  The set
$\ground(\sigma, D)$ is the familiar Herbrand base in logic
programming.  Note that each ground atom is prefixed by a relation
name.

Let $\bm P$ be a POPS.  A {\em $\bm P$-instance for $\sigma$} is a function
$I : \ground(\sigma, D) \rightarrow \bm P$ with {\em finite support},
where the support is defined as the set of ground atoms that are
mapped to elements {\em other than} $\bot$.
For example, if $\bm P$ is a naturally ordered semiring, then the support of the function
$I$ is the number of ground atoms assigned to a non-zero value.
The {\em active domain} of the instance $I$,
denoted by $\adom(I)$, is the finite set $\adom(I) \subseteq D$ of all constants that occur
in the support of $I$.  We denote by $\inst(\sigma, D, \bm P)$ the set
of $\bm P$-instances over the domain $D$.  When $\sigma$ consists of a
single relation name, then we call $I$ a {\em $\bm P$-relation}.

An equivalent way to define a $\bm P$-instance is as a function
$I : \ground(\sigma, D_0) \rightarrow \bm P$, for some finite subset
$D_0 \subseteq D$; by convention, this function is extended to the
entire set $\ground(\sigma, D)$ by setting $I(a) := \bot$ for all
$a \in \ground(\sigma,D) \setminus \ground(\sigma,D_0)$.  The set
$\inst(\sigma, D_0, \bm P)$ is isomorphic to $P^N$, where
$N=|\ground(\sigma, D_0)|$, and, throughout this paper, we will
identify a $\bm P$-instance with a tuple in $P^N$.

Thus, a $\bm P$-instance involves two domains: $D$, which is called
the {\em key space}, and the POPS $\bm P$, which is called the {\em
  value space}.  For some simple illustrations, a $\B$-relation is a
standard relation where every ground tuple is either true or false,
while an $\R$-relation is a sparse tensor.\remy{$R$ is not a POPS.}

\subsection{(Sum-)Sum-Product Queries on POPS}
\label{subsec:sum-products}

In the Boolean world, conjunctive queries and union of conjunctive
queries are building-block queries.  Analogously, in the POPS world,
we introduce the concepts of {\em sum-product queries} and {\em
  sum-sum-product queries}.\remy{The parallel is misleading.}
In the simplest setting, these queries
have been studied in other communities (especially AI and machine
learning as reviewed below).  In our setting, we need to introduce one
extra feature called ``conditional'', in order to cope with the fact
that $0$ is not absorptive.

% However, there are two extra features of these queries that we deal with explicitly in our
% work: they can be {\em recursive}, and they operate under POPS instead of the usual
% sum-product semiring over the reals.
% 
% First, recursive sum-sum-product queries are generalizations of Datalog to POPS. There is a
% a rich landscape of convergence behavior that we open up a study of.
% Second, the fact that the bottom element $\bot$ is not necessarily the additive identity $0$
% of the semiring leads to subtle but necessary complications in how we formulate these
% queries, as shall be explained below with the notion of "conditional" (sum-)sum-product
% queries.
% 
% \dan{We should clarify the discussion of recursive queries and datalog
%   above.  Right now it's confusing because in this section we do not
%   mention recursive queries.  Maybe we should say that we will
%   introduce \datalogo in Sec.~\ref{sec:datalogo}.}

% We now introduce these classes of queries.
Fix two disjoint vocabularies, $\sigma, \sigma_\B$; the relation names
in $\sigma$ will be interpreted over a POPS $\bm P$, while those in
$\sigma_\B$ will be interpreted over the Booleans.  Let $D$ be a
domain, and $V = \set{X_1, \ldots, X_p}$ a set of ``key variables''
whose values are over the key space $D$. They should not be
confused with variables used in polynomials, which are interpreted
over the POPS $\bm P$; we refer to the latter as ``value variables'' to
contrast them with
the key variables.
We use upper case for key variables, and
lower case for value variables.  A {\em $\sigma$-atom} is an expression
of the form $R_i(\bm X)$, where $R_i \in \sigma$ and $\bm X \in (V \cup D)^{\text{arity}(R_i)}$.
% (Recall that the set of all atoms of the form $R_i(X)$ for $X \in D^{\text{arity}(R_i)}$
% is the familiar {\em Herbrand Base} in logic programming.)

\begin{defn} \label{def:sum:product} A (conditional) {\em sum-product query}, or
{\em sum-product rule} is an expression of the form
%
  \begin{align}
    T(X_1, \ldots, X_k) &\cd \bigoplus_{X_{k+1}, \ldots,X_p} \setof{R_1(\bm X_1) \otimes
    \cdots \otimes R_m(\bm X_m)}{\Phi(V)}  \label{eq:t:monomial}
  \end{align}
%
  where $T$ is a new relation name of arity $k$, each $R_j(\bm X_j)$
  is a $\sigma$-atom, and $\Phi$ is a first-order (FO) formula over\remy{What is the range of $\forall$?}
  $\sigma_\B$, whose free variables are in
  $V = \set{X_1, \ldots, X_p}$.  The LHS of $\cd$ is called the {\em
    head}, and the RHS the {\em body} of the rule.  The variables
  $X_1, \ldots, X_k$ are called {\em free variables} of the query
  (also called {\em head variables}), and $X_{k+1}, \ldots, X_p$ are
  called {\em bound variables}.
\end{defn}

{\em Without} the conditional term $\Phi$,
the problem of computing efficiently sum-products over semirings has
been extensively studied both in the database and in the AI
literature. In databases, the query optimization and evaluation
problem is a special case of sum-product computation over the
value-space of Booleans (set semantics) or natural numbers (bag
semantics). The functional aggregate queries (FAQ)
framework~\cite{DBLP:conf/pods/KhamisNR16} extends the formulation to
queries over multiple semirings. In AI, this problem was studied by
Shenoy and Schafer~\cite{DBLP:conf/uai/ShenoyS88},
Dechter~\cite{DBLP:journals/constraints/Dechter97}, Kohlas and
Wilson~\cite{DBLP:journals/ai/KohlasW08} and others.  Surveys and more
examples can be found
in~\cite{DBLP:journals/tit/AjiM00,DBLP:books/daglib/0008195}.  These
methods use a sparse representation of the $\bm P$-relations,
consisting of a collection of the tuples in their support.

The use of a conditional $\Phi$ in the sum-product is non-standard,
but it is necessary for sum-product expressions over a POPS that is
not a semiring, as we illustrate next.
% We will define its semantic shortly; before doing so, let us illustrate the motivation
% for $\Phi$'s existence with an example.

\begin{ex} \label{ex:conditional:sum:product}
  Let $E(X,Y)$ be a $\B$-relation (i.e. a standard relation),
  representing a graph.  The following sum-product expression over $\B$ computes
  all pairs of nodes connected by a paths of length 2:
  %
  \begin{align*}
      T(X,Z) & \cd \exists_Y \left(E(X,Y) \wedge E(Y,Z)\right)
  \end{align*}
  %
  This is a standard conjunctive
  query~\cite{DBLP:books/aw/AbiteboulHV95} (where the semantics of
  quantification over $Y$ is explicitly written).  Here
  $\sigma = \set{E}$, and $\sigma_\B = \emptyset$: we do not need the
  conditional term $\Phi$ yet.\remy{Remove this example?}

  For the second example, consider the same graph given by $E(X,Y)$,
  and let $C(X)$ be an $\R_\bot$-relation associating to each node $X$
  a real number representing a cost, or $\bot$ if the cost is unknown;
  now $\sigma = \set{C}, \sigma_\B = \set{E}$.  The following
  sum-product expression computes the total costs of all neighbors of
  $X$:
  %
  \begin{align}
    T(X) \cd & \sum_Y \setof{C(Y)}{E(X,Y)} \label{eq:explicit:conditional}
  \end{align}
  %
  Usually, conditionals are avoided by using an indicator function
  $1_{E(X,Y)}$, which is defined to be $1$ when $E(X,Y)$ is true and
  $0$ otherwise, and writing the rule as
  $T(X) \cd \sum_Y \left(1_{E(X,Y)}\cdot C(Y)\right)$.  But this does
  not work in $\R_\bot$, because, when $Y$ is mapped to a
  non-neighboring node which so happens to have an unknown cost (while
  all neighbors' costs are known), we have $C(Y) = \bot$. In this
  case, $1_{E(X,Y)} \cdot C(Y) = 0 \cdot \bot = \bot$, instead of
  $0$. Since $x + \bot = \bot$ in $\R_\bot$, the result is also
  $\bot$.  One may ask whether we can re-define the POPS $\R_\bot$ so
  that $\bot \cdot 0 = 0$, but we show in
  Lemma~\ref{lemma:no:extension:for:r} that this is not possible.  The
  explicit conditional in~\eqref{eq:explicit:conditional} allows us to
  restrict the range of $Y$ only to the neighbors of $X$.
\end{ex}

We now formally define the semantics of (conditional) sum-product queries.
Due to the subtlety with POPS, we need to consider an alternative approach to evaluating
the results of sum-product queries: first compute the {\em provenance polynomials} of
the query~\eqref{eq:t:monomial} to obtain the component polynomials of a vector-valued
function, then evaluate these polynomials.  The provenance polynomials, or simply
provenance, are also called lineage, or groundings in the literature~\cite{DBLP:conf/pods/GreenKT07}.

% \hqn{Need a citation above}
% \dan{Done}

Given an input instance $I_\B \in \inst(\sigma_\B, D, \B)$,
$I \in \inst(\sigma, D, \bm P)$, and let $D_0 \subseteq D$ be the
finite set consisting of their active domains and all constants
occurring in the sum-product expression~\eqref{eq:t:monomial}.  Let
$N \defeq |\ground(\sigma, D_0)|$ and
$M \defeq |\ground(T,D_0)| = |D_0|^k$ be the number of input ground
atoms and output ground atoms respectively.

To each of the $N$ input atoms $\ground(\sigma,D_0)$ we associate a unique POPS variable
$x_1, \ldots, x_N$. (Recall that we use upper case for key variables and
lower case for value variables.)
Abusing notation, we also write $x_{R(\bm u)}$ to mean the variable associated to the ground
atom $R(\bm u)$.
A {\em valuation} is a function $\theta : V \rightarrow D_0$.
When applied to the body of the rule~\eqref{eq:t:monomial}, the valuation $\theta$ defines the
following monomial:
%
\begin{align}
  \theta(\text{body}) \defeq & x_{R_1(\theta(\bm X_1))}\cdot x_{R_2(\theta(\bm X_2))} \cdot \ldots \cdot x_{R_m(\theta(\bm X_m))} \label{eq:grounding:monomial}
\end{align}
%
The {\em provenance polynomial}~\cite{DBLP:conf/pods/GreenKT07} of the output tuple
$T(\bm a) \in \ground(T,D_0)$ is the following:
%
\begin{align}
  f_{T(\bm a)}(x_1, \ldots, x_N) \defeq &
  \sum_{\substack{\theta: V \rightarrow D_0, \\ \theta(X_1,\ldots,X_k)=\bm a, \\ I_\B \models
  \Phi[\theta]}} \theta(\text{body}) \label{eq:grounding:polynomial}
\end{align}
%
In other words, we consider only valuations $\theta$ that map the head\remy{Should the head vars be $X_1, \ldots, X_k$?}
variables to the tuple $\bm a$ and satisfy the FO sentence $\Phi$.
There are $M$ provenance polynomials, one for each tuple in
$\ground(T,D_0)$, and they define an $M$-tuple of polynomials in $N$
variables, $\bm f$, which in turn defines a function
$\bm f : \bm P^N \rightarrow \bm P^M$.  The semantics of the
query~\eqref{eq:t:monomial} is defined as the value of this polynomial
on the input instance $I \in \inst(\sigma, D_0, \bm P)$, when viewed
as a tuple $I \in \bm P^N$.

Note that, once we have constructed the provenance polynomial, we no longer need to deal with the
conditional $\Phi$, because the grounded version does not have $\Phi$ anymore.
In most of the rest of the paper we will study properties of vector-valued
functions whose components are these provenance polynomials.

We notice that, as defined, our semantics depends on the choice of the
domain $D_0$: if we used a larger finite domain $D'_0 \supseteq D_0$,
then the provenance polynomials will include additional spurious
monomials, corresponding to the spurious grounded tuples in $D_0'$.
Traditionally, these spurious monomials are harmless, because their
value is 0.  However, in our setting, their value is $\bot$, and they
may change the result.  This is precisely the role of the conditional
$\Phi$ in~\eqref{eq:t:monomial}: to control the range of the variables
and ensure that the semantics is domain independent.  All examples in
this paper are written such that they are domain independent.

Finally, (conditional) sum-sum-product queries are defined in the natural way:

\begin{defn} \label{def:sum:sum:product}
    A (conditional) {\em sum-sum-product query} or {\em sum-sum-product rule} has the
  form:
%
\begin{align}
  T(X_1, \ldots, X_k) &\cd E_1 \oplus \cdots \oplus E_q \label{eq:sum:sum:product}
  \end{align}
%
  where $E_1, E_2, \ldots, E_q$ are the bodies of sum-product
  expressions~\eqref{eq:t:monomial}, each with the same free variables
  $X_1, \ldots, X_k$.
\end{defn}

The provenance polynomials of a sum-sum-product query are defined as
the sum of the provenance polynomials of the expressions
$E_1, \ldots, E_q$.

For a simple illustration, we show a modification
of~\eqref{eq:explicit:conditional} where we include in the total sum
$T(X)$ the cost of $X$:
%
\begin{align*}
    T(X) \cd & C(X) + \sum_Y \setof{C(Y)}{E(X,Y)}
\end{align*}

\subsection{Properties and Examples of POPS}
\label{subsec:examples:pops}

We end this section by presenting several properties of POPS and
illustrating them  with a few examples.

\subsubsection{Extending Pre-semirings to POPS}

If $\bm S$ is a pre-semiring, then we say that a POPS $\bm P$ {\em
extends} $\bm S$ if $S \subseteq P$ ($S$ and $P$ are their domains), and the
operations $\oplus, \otimes, 0, 1$ in $\bm S$ are the same as those in $\bm P$.
We describe three procedures to extend a pre-semiring $\bm S$ to a
POPS $\bm P$, inspired by abstract interpretations in programming
languages~\cite{DBLP:conf/popl/CousotC77}.

\begin{description}
\item[Representing Undefined] The {\em lifted POPS} is
  $\bm S_\bot = (S \cup \set{\bot}, \oplus, \otimes, 0, 1,
  \sqsubseteq)$, where $x \sqsubseteq y$ iff $x = \bot$ or $x = y$,
  and the operations $\oplus, \otimes$ are extended to $\bot$ by
  setting $x \oplus \bot = x \otimes \bot = \bot$.  Notice that
  $\bm S_\bot$ is not a semiring, because $0$ is not absorbing:
  $0 \otimes \bot \neq 0$.  Its core semiring is the trivial semiring
  $S_\bot \oplus \bot = \set{\bot}$.  Here $\bot$ represents {\em
    undefined}.

\item[Representing Contradiction] The {\em completed POPS} is
  $\bm S_\bot^\top = (S \cup \set{\bot, \top}, \oplus, \otimes, 0, 1,
  \sqsubseteq)$, where $x \sqsubseteq y$ iff $x=\bot$, $x=y$, or
  $y=\top$ and the operations $\oplus, \otimes$ are extended to
  $\bot, \top$ as follows: $x \oplus \bot = x \otimes \bot = \bot$ for
  all $x$ (including $x=\top$), and
  $x \oplus \top = x \otimes \top = \top$ for all $x \neq \bot$.  As
  before, its core semiring is the trivial semiring
  $S_\bot^\top \oplus \bot = \set{\bot}$.  Here $\bot, \top$ represent
  undefined and contradiction respectively.  Intuitively: $\bot$ is
  the empty set $\emptyset$, each element $x \in \bm S$ is a singleton
  set consisting of one value, and $\top$ is the entire set $S$.

\item[Representing Incomplete Values] More generally, define
  $\calP(\bm S) = (\calP(S), \oplus, \otimes, \set{0}, \set{1}, \subseteq)$.  It
  consists of all subsets of $\bm S$, ordered by set inclusion, where
  the operations $\oplus, \otimes$ are extended to sets, e.g.
  $A \oplus B = \setof{x\oplus y}{x \in A, y \in B}$.  Its core
  semiring is itself, $\calP(\bm S) \oplus \set{0} = \calP(\bm S)$.
  Here $\bot=\emptyset$ represents undefined, $\top=S$ represents
  contradiction, and, more generally, every set represents some degree
  of incompleteness.
\end{description}


A lifted POPS $\bm S_\bot$ is never a semiring, because
$\bot \otimes 0 = \bot$, and the reader may ask whether there exists
an alternative way to extend it to a POPS that is also a semiring,
i.e. $0 \otimes x = 0$.  For example, we can define
$\N \cup \set{\bot}$ as a semiring by setting $x + \bot = \bot$ for
all $x$, $0 \mult \bot = 0$ and $x \mult \bot = \bot$ for $x > 0$: one can
check that the semiring laws hold.  However, this is not possible in
general.  We prove:

\begin{lmm} \label{lemma:no:extension:for:r} If $\bm S$ is any POPS
  extension of $(\R, +, \mult, 0, 1)$, then $\bm S$ is not a semiring,
  i.e. it fails the absorption law $0 \mult x = 0$.
\end{lmm}
\begin{proof}
  Let $\bm S = (S, +, \mult, 0, 1, \sqsubseteq)$ be any POPS that is an
  extension of $\R$.  In particular $\R \subseteq S$ and $S$ has a
  minimal element $\bot$.  Since 0, 1 are additive and multiplicative identities,
  we have:
%
  \begin{align*}
    \bot+0 &= \bot & \bot \mult 1 &= \bot
  \end{align*}
%
  We claim that the following more general identities hold:
%
  \begin{align*}
    \forall x \in \R:\  \bot+x = & \bot & \forall x \in \R \setminus \set{0}: \bot \mult x = & \bot
  \end{align*}
%
  To prove the first identity, we use the fact that $+$ is monotone in
  $\bm S$ and $\bot$ is the smallest element, and derive
  $\bot + x \sqsubseteq (\bot + (y-x)) +x = \bot + y$ for all
  $x,y\in\R$.  This implies $\bot + x = \bot + y$ for all $x,y$ and
  the claim follows by setting $y=0$.  The proof of the second
  identity is similar: first observe that
  $\bot \mult x \sqsubseteq (\bot \mult \frac{y}{x}) \mult x=\bot
  \mult y$ hence $\bot \mult x = \bot \mult y$ for all
  $x, y \in \R \setminus \set{0}$, and the claim follows by setting
  $y=1$.

  Assuming $\bm S$ is a semiring, it satisfies the absorption law:
  $\bot \mult 0 = 0$.  We prove now that $0 = \bot$.  Choose any
  $x \in \R \setminus \set{0}$, and derive:
%
  \begin{align*}
    \bot = \bot + \bot =
    (\bot  \mult  x) + (\bot \mult (-x))
    = \bot \mult (x+(-x)) &= \bot  \mult  0 = 0.
  \end{align*}
%
  The middle identity follows from distributivity. From $0 = \bot$, we
  conclude that $0$ is the smallest element in $\bm S$.  Then, for
  every $x \in \R$, we have $x = x+0 \sqsubseteq x+(-x) = 0$, which
  implies $x = 0$, $\forall x \in \R$, which is a contradiction.
  Thus, $\bm S$ is not a semiring.
\end{proof}

\subsubsection{The POPS THREE} \label{subsec:three:pops}

Consider the following POPS:
$\texttt{THREE} \defeq (\set{\bot, 0,  1}, \vee, \wedge,  0,
 1, \leq_k)$, where:
  %
\begin{itemize}
\item $\vee, \wedge$ have the semantics of 3-valued
  logic~\cite{DBLP:journals/jlp/Fitting85a}.  More precisely, define
  the {\em truth ordering} $0 \leq_t \bot \leq_t 1$ and set
  $x \vee y \defeq \max_t(x,y)$, $x \wedge y \defeq \min_t(x,y)$.  We
  note that this is precisely Kleene's three-valued
  logic~\cite{DBLP:journals/logcom/Fitting91}.
\item $\leq_k$ is the {\em knowledge order\/}, defined as
  $\bot <_k  0$ and $\bot <_k  1$.
\end{itemize}
%
$\texttt{THREE}$ is not the same as the lifted Booleans, $\B_\bot$,
because in the latter $0 \wedge \bot = \bot$, while in
$\texttt{THREE}$ we have $0 \wedge \bot = 0$.  Its core semiring is
$\texttt{THREE} \vee \bot = \set{\bot, 1}$, and is isomorphic to $\B$.
We will return to this POPS in Sec.~\ref{sec:fitting}.

\subsubsection{Stable Semirings}
\label{subsec:stable:semirings}

We illustrate here two examples of semirings that are {\em stable}, a
property that we define formally in Sec.~\ref{sec:complexity}.  Both
examples are adapted from~\cite[Example 7.1.4]{semiring_book}
and~\cite[Chapt.8, Sec.1.3.2]{semiring_book} respectively.  If $A$ is
a set and $p \geq 0$ a natural number, then we denote by $\calP_p(A)$
the set of subsets of $A$ of size $p$, and by $\calB_p(A)$ the set of
bags of $A$ of size $p$.  We also define
\begin{align*}
    \calP_{\texttt{fin}}(A) &\defeq \bigcup_{p\geq 0}\calP_p(A) &
    \calB_{\texttt{fin}}(A) & \defeq \bigcup_{p\geq 0}\calB_p(A).
     &
\end{align*}
We denote bags as in $\bag{a,a,a,b,c,c}$.  Given
$\bm x,\bm y \in \calP_{fin}(\R_+ \cup \infty)$, we denote by:
%
\begin{align*}
  \bm x \cup \bm y \defeq & \mbox{set union of $\bm x,\bm y$} &
  \bm x + \bm y \defeq & \setof{u+v}{u \in \bm x, v \in \bm y}
\end{align*}
%
Similarly, given $\bm x,\bm y \in \calB_{fin}(\R_+ \cup \infty)$, we denote
by:
%
\begin{align*}
  \bm x \uplus \bm y \defeq & \mbox{bag union of $\bm x,\bm y$} &
  \bm x + \bm y \defeq & \bagof{u+v}{u \in \bm x, v \in \bm y}
\end{align*}


\begin{ex} \label{ex:trop:p} For any bag
  $\bm x = \bag{x_0, x_1, \ldots, x_n}$, where
  $x_0\leq x_1 \leq \ldots \leq x_n$, and any $p \geq 0$, define:
  %
  \begin{align*}
    {\min}_p(\bm x) \defeq & \bag{x_0, x_1, \ldots, x_{\min(p,n)}}
  \end{align*}
  %
  In other words, $\min_p$ returns the smallest $p+1$ elements of the
  bag $\bm x$.  Then, for any $p \geq 0$, the following is a semiring:
  %
  \begin{align*}
    \trop^+_p \defeq & (\calB_{p+1}(\R_+\cup\set{\infty}), \oplus_p, \otimes_p, \bm 0_p, \bm 1_p)
  \end{align*}
  %
  where:
  %
  \begin{align*}
    \bm x \oplus_p \bm y \defeq & {\min}_p(\bm x \uplus \bm y) &
    \bm 0_p \defeq & \set{\infty, \infty, \ldots, \infty} \\
    \bm x \otimes_p \bm y \defeq & {\min}_p(\bm x + \bm y) &
    \bm 1_p \defeq & \set{0,\infty, \ldots, \infty}
  \end{align*}
  %
  For example, if $p=2$ then
  $\bag{3,7,9} \oplus_2 \bag{3,7,7} = \bag{3,3,7}$ and
  $\bag{3,7,9} \otimes_2 \bag{3,7,7} = \bag{6,10,10}$.
  %
  The following identities are easily checked, for any two finite bags
  $\bm x, \bm y$:
  %
  \begin{align}
    {\min}_p({\min}_p(\bm x) \uplus {\min}_p(\bm y))= & {\min}_p(\bm x \uplus \bm y)&
    {\min}_p({\min}_p(\bm x) + {\min}_p(\bm y))= & {\min}_p(\bm x + \bm y) \label{eq:minp:identity}
  \end{align}
  %
  This implies that, an expression in the semiring $\trop^+_p$ can be
  computed as follows.  First, convert $\oplus, \otimes$ to
  $\uplus, +$ respectively, compute the resulting bag, then apply
  $\min_p$ only once, on the final result. $\trop^+_p$ is naturally
  ordered (see Prop~\ref{prop:trop:p:stable}) and therefore its core
  semiring is itself, $\trop^+_p \oplus_p \bm 0_p = \trop^+_p$.
%
% \reinhard{As discussed on 14 December, we will introduce a name for the semiring obtained as the set of $x+\bot$ elements of a POPS.}
%
  When $p=0$, then $\trop^+_p = \trop^+$, which we introduced in
  Example~\ref{ex:intro}.
\end{ex}

\begin{ex} \label{ex:trop:eta} Fix a real number $\eta \geq 0$, and
  denote by $\calP_{\leq \eta}(\R_+\cup\set{\infty})$ the set of
  nonempty, finite sets $\bm x = \set{x_0, x_1, \ldots, x_p}$ where
  $\min(\bm x) \leq \max(\bm x)\leq \min(\bm x) + \eta$.  Given any
  finite set $\bm x \in \calP_{\texttt{fin}}(\R_+\cup\set{\infty})$,
  we define
  %
  \begin{align*}
    {\min}_{\leq \eta}(\bm x) \defeq & \setof{u}{u \in \bm x, u \leq \min(\bm x) + \eta}
  \end{align*}
  %
  In other words, $\min_{\leq \eta}$ retains from the set $\bm x$ only
  the elements at distance $\leq \eta$ from its minimum.  The
  following is a semiring:
  %
  \begin{align*}
    \trop^+_{\leq\eta} \defeq & (\calP_{\leq \eta}(\R_+\cup\set{\infty}),\oplus_{\leq\eta},\otimes_{\leq\eta},\bm 0_{\leq\eta},\bm 1_{\leq\eta})
  \end{align*}
  %
  where:
  %
  \begin{align*}
    \bm x \oplus_{\leq\eta} \bm y \defeq & {\min}_{\leq\eta}(\bm x \cup \bm y) &
    \bm 0_{\leq\eta} \defeq & \set{\infty} \\
    \bm x \otimes_{\leq\eta} \bm y \defeq & {\min}_{\leq\eta}(\bm x + \bm y)&
    \bm 1_{\leq\eta} \defeq & \set{0}
   \end{align*}
   %
   For example, if $\eta = 6.5$ then:
   $\set{3,7} \oplus_{\leq \eta} \set{5,9,10} = \set{3,5,7,9}$ and
   $\set{1,6} \otimes_{\leq \eta} \set{1,2,3} = \set{2,3,4,7,8}$.
   %
   The following identities are easily checked, for any two finite
   sets $\bm x, \bm y$:
     %
  \begin{align}
    {\min}_{\leq \eta}({\min}_{\leq \eta}(\bm x) \cup {\min}_{\leq \eta}(\bm y))= & {\min}_{\leq \eta}(\bm x \cup \bm y)&
    {\min}_{\leq \eta}({\min}_{\leq \eta}(\bm x) + {\min}_{\leq \eta}(\bm y))= & {\min}_{\leq \eta}(\bm x + \bm y) \label{eq:mineta:identity}
  \end{align}
  %
  It follows that expressions in $\trop^+_{\leq\eta}$ can be computed
  as follows: first convert $\oplus, \otimes$ to $\cup, +$
  respectively, compute the resulting set, and apply the
  $\min_{\leq\eta}$ operator only once, on the final result.
  %
  $\trop^+_{\leq \eta}$ is naturally ordered (see
  Prop.~\ref{prop:trop:eta:stable}) and therefore its core semiring is
  itself,
  $\trop^+_{\leq \eta}\oplus_{\leq \eta} \bm 0_{\leq \eta} =
  \trop^+_{\leq\eta}$.
%
% \reinhard{Same as previous comment: we will have a name for this semiring inside a POPS.}
%
  Notice that, when $\eta=0$, then we recover again
  $\trop^+_{\leq \eta} = \trop^+$.
\end{ex}

The reader may wonder why $\trop^+_p$ is defined to consist of bags of
$p+1$ numbers, while $\trop^+_{\leq \eta}$ is defined on sets.  The main
reason is for consistency with~\cite{semiring_book}.  We could have
defined either semirings on either sets or bags, and both
identities~\eqref{eq:minp:identity} and ~\eqref{eq:mineta:identity}
continue to hold, which is sufficient to prove the semiring
identities.  However, the {\em stability} property which we define and
prove later (Proposition~\ref{prop:trop:eta:stable}) holds for
$\trop^+_{\leq \eta}$ only if it is defined over sets; in contrast,
$\trop^+_p$ is stable for either sets or bags
(Proposition~\ref{prop:trop:p:stable}).

\subsubsection{Nontrivial Core Semiring}

In all our examples so far the core semiring $\bm P \oplus \bot$ is
either $\set{\bot}$ or $\bm P$.  We show next that the core semiring
may be non-trivial.  If $\bm P_1, \bm P_2$ are two POPS, then their
Cartesian product $\bm P_1 \times \bm P_2$ is also a POPS: operations
are defined element-wise, e.g.
$(x_1,x_2) \oplus (y_1,y_2) \defeq (x_1\oplus_1 y_1, x_2 \oplus_2
y_2)$, etc, the order is defined component-wise, and the smallest
element is $(\bot_1, \bot_2)$.

\begin{ex} Consider the following two POPS.
  \begin{itemize}
  \item A naturally ordered semiring
    $\bm S = (S, \oplus_S, \otimes_S, 0_S, 1_S, \sqsubseteq_S)$.  Its
    core semiring is itself $\bm S \oplus_S 0_S=\bm S$.
  \item Any POPS $\bm P$ where addition is strict:
    $x \oplus_P \bot = \bot$.  (For example, any lifted semiring.)
    Its core semiring is $\bm P \oplus_P \bot_P = \set{\bot_P}$.
  \end{itemize}
  %
  Consider the Cartesian product $\bm S \times \bm P$.  The smallest
  element is $(0_S,\bot_P)$, and the core semiring is
  $(\bm S \times \bm P) \oplus (0_S,\bot_P) = \bm S \times
  \set{\bot_P}$, which is a non-trivial subset of
  $\bm S \times \bm P$.
\end{ex}

\section{\datalogo}
\label{sec:datalogo}

We define here the language \datalogo, which generalizes datalog from
traditional relations to $\bm P$-relations, for some POPS $\bm P$.  As
in datalog, the input relations to the program will be called
Extensional Database Predicates, EDB, and the computed relations will
be called Intensional Database Predicates, IDB.  Each EDB can be
either a $\bm P$-relation, or standard relation, i.e. a $\B$-relation,
and we denote by $\sigma \defeq \set{R_1, \ldots, R_m}$ and
$\sigma_\B \defeq \set{B_1, \ldots, B_k}$ the two vocabularies.  All
IDBs are $\bm P$-relations, and their vocabulary is denoted by
$\tau = \set{T_1, \ldots, T_n}$.

A \datalogo program $\Pi$ consists of $n$ sum-sum-product rules
$r_1, \ldots, r_n$ (as in Definition~\ref{def:sum:sum:product}), where
each rule $r_i$ has the IDB $T_i$ in the head:
%
\begin{align}
  r_1: T_1(\cdots) & \cd E_{11}\oplus E_{12} \oplus \cdots \nonumber \\
       & \ldots \label{eq:basic:datalogo} \\
  r_n: T_n(\cdots) & \cd E_{n1} \oplus E_{n2} \oplus \cdots, \nonumber
\end{align}
%
and each $E_{ij}$ is a sum-product expression as
in~\eqref{eq:t:monomial}.  The program $\Pi$ is said to be {\em
  linear} if each sum-product expression $E_{ij}$ contains at most one
IDB predicate.

\subsection{Least Fixpoint of the Immediate Consequence Operator}

\label{subsec:ico}

The {\em Immediate Consequence Operator} (ICO) of a program
$\Pi$ is the function
$F : \inst(\sigma,D,\bm P) \times \inst(\sigma_\B,D,\B) \times
\inst(\tau,D,\bm P) \rightarrow \inst(\tau,D,\bm P)$, that takes as
input an instance $(I, I_\B)$ of the EDBs and an instance $J$ of the
IDBs, and computes a new instance $F(I,I_\B,J)$ of the IDBs by
evaluating each sum-sum-product rule.  By fixing the EDBs, we will
view the ICO as function from IDBs to IDBs, written as $F(J)$. We
define the {\em semantics} of the \datalogo
program~\eqref{eq:basic:datalogo} as the least fixpoint of the ICO
$F$, when it exists.

\begin{algorithm}[th]
     $J^{(0)} \leftarrow \bot\mbox{;}$ \mbox{\hspace{2cm} // In a naturally ordered  semiring this becomes $J^{(0)} \leftarrow 0$}\\
    \For {  $t \leftarrow 0$   {\bf to}   $\infty$ }
    {
         {$J^{(t+1)} \leftarrow F(J^{(t)})$}\;
        \If { $J^{(t+1)} = J^{(t)}$ }{
           Break
        }
    }
    \Return $J^{(t)}$
    \caption{Na\"ive evaluation for \datalogo
%       \\ In Sec.~\ref{sec:semi:naive} the POPS $\bm P$
%       is a naturally ordered semiring, and the first line becomes
%       $J^{(0)} \leftarrow 0$.
    }
    \label{algo:naive}
\end{algorithm}

The Na\"ive Algorithm for evaluating \datalogo is shown in
Algorithm~\ref{algo:naive}, and it is quite similar to that for
standard, positive datalog with set semantics.  We start with all IDBs
at $\bot$, then repeatedly apply the ICO $F$, until we reach a
fixpoint.
% \hqn{Should we mention that $F$ is monotone and thus a LFP is guaranted to exists?}
% \dan{It may not exists in general, it depends on $\bm P$.}
The algorithm computes the increasing sequence
$\bot \sqsubseteq F(\bot) \sqsubseteq F^{(2)}(\bot)
\sqsubseteq \cdots$ When the algorithm terminates we say that it {\em
  converges}; in that case it returns the least fixpoint of $F$.
Otherwise we say that the algorithm {\em diverges}.

% We will show in Sec.~\ref{sec:semi:naive} that, when evaluated over a
% naturally ordered semiring with some additional properties, the naive
% algorithm can be improved to a semi-na\"ive algorithm; in that case,
% $\bot$ coincides with $\bm 0$, hence the first line of the na\"ive
% algorithm becomes $I^{(0)} \leftarrow \bm 0$.

\subsection{Convergence of \datalogo Programs}

\label{subsec:five:cases}

% \hqn{``Divergence'' typically means going a way from convergence. Here we use ``divergence''
% to mean ``not converged in a finite number of steps'', which can be mis-leading.
% In many papers, the LFP for a monotone $f$
% is defined to be $f^\omega := \lim_{n\to \infty} f^n$;
% and in those cases I would say that sequence $f^n$ {\em converges}.
% As mentioned in an earlier comment, we probably need 5 categories intead of 4.
% }
% \dan{Hung, did you want a discussion of the five cases here?  I wrote
%   one, tentatively, but I believe it is more suited in
%   Sec.~\ref{sec:complexity}, because we refer to the
%   program~\eqref{eq:datalogo:linear}.  We have already a discussion
%   there, we can just add a 5th case.  So feel free to delete this
%   section, or integrate in Sec.~\ref{sec:complexity}.}

While every pure datalog program is guaranteed to have a least
fixpoint, this no longer holds for \datalogo programs.  As we mentioned
in the introduction, there are five possibilities, depending on the
POPS $\bm P$:

\begin{enumerate}[label=(\roman*)]
\item $\bigvee_t J^{(t)}$ is not a fixpoint of the ICO; in this case
  we say that the program {\em diverges}.
%   For example, if we
%   interpret the program~\eqref{eq:datalogo:linear} over $\N$ and set
%   $c > 1$, then the sequence of IDBs computed by the na\"ive algorithm
%   is $0 < 1+c < 1+c+c^2 < \cdots$, which has no least upper bound in
%   $\N$.  One can construct POPS where $\bigvee_n J^{(n)}$ always
%   exists, but is not the least fixpoint.
\item $\bigvee_n J^{(n)}$ is always the least fixpoint, but the
  na\"ive algorithm does not always terminate.  With some abuse we say
  also in this case that the program {\em diverges}.
  % lub is not reached in a finite number of steps; equivalently, the
  % sequence $J^{(n)}$ is strictly increasing.  With some abuse we
  % also say that the program {\em diverges}.  For example, if we
  % interpret the program~\eqref{eq:datalogo:linear} over
  % $\N \cup \set{\infty}$, then any increasing sequence has a lub,
  % but if the lub is $\infty$ then the na\"ive algorithm will not
  % terminate in a finite number of steps.
\item The na\"ive algorithm always terminates, in which case we say
  that it {\em converges}.  The number of steps depends on the input
  EDB database, meaning {\em both} the number of ground atoms in the
  EDB, and their values in $\bm P$.
\item The na\"ive algorithm always terminates in a number of steps
  that depends only on the number of ground atoms in the EDB, but not
  on their values.
\item The na\"ive algorithm always terminates in a number of steps
  that is polynomial in the number of ground atoms in the EDB.
\end{enumerate}

In this paper we are interested in characterizing the POPS that ensure
that every \datalogo program converges.  At a finer level, our goal is
to characterize precisely
cases~\ref{item:converge:3}-\ref{item:converge:5}.  We will do this in
Sec.~\ref{sec:complexity}, and, for that purpose, we will use an
equivalent definition of the semantics of a \datalogo program, namely as
the least fixpoint of a tuple of polynomials, obtained by grounding
the program.

\subsection{Least Fixpoint of the Grounded Program}

\label{subsec:grounded:program}

In this paper we consider an equivalent semantics of \datalogo, which
consists of first grounding the program, then computing its least
fixpoint.

% %
% \reinhard{
% As before, we just say "Fix a POPS P". Should we say "Fix a strict POPS P"?
% }
% \dan{we say early that all POPS are assumed to be strict in this paper}
% %
Fix an EDB instance $I, I_\B$, and let $D_0 \subseteq D$ be the finite
set consisting of its active domain plus all constants occurring in
the program $\Pi$.  Let $M = |\ground(\sigma,D_0)|$ and
$N = |\ground(\tau,D_0)|$ be the number of ground tuples of the EDBs
and the IDBs respectively.  We associate them in 1-to-1 correspondence
with $M+N$ POPS variables $z_1, \ldots, z_M$ and $x_1, \ldots, x_N$,
and use the same notation as in Sec.~\ref{subsec:sum-products} by
writing $x_{T_i(\bm a)}$ for the variable associated to the ground
tuple $T_i(\bm a)$.

Consider a rule $T_i(\cdots) \cd E_{i1} \oplus E_{i2} \oplus \cdots$
of the \datalogo program, with head relation $T_i$.  A {\em grounding}
of this rule is a rule of the form:
%
\begin{align*}
  x_{T_i(\bm a)} \cd & f_{T_i(\bm a)}(z_1, \ldots, z_M, x_1, \ldots, x_N)
\end{align*}
%
where $T_i(\bm a) \in \ground(T_i,D_0)$ is a ground tuple, and
$f_{T_i(\bm a)}$ is the {\em provenance polynomial} (defined in
Sec.~\ref{subsec:sum-products}) of the rule's body
$E_{i1} \oplus E_{i2} \oplus \cdots$ Since the value of each EDB
variable $z_{R_i(\bm u)}$ is known, we can substitute it with its
value, and the provenance polynomial simplifies to one that uses only
IDB variables $x_j$; we will no longer refer to the EDB variables
$z_i$.  The {\em grounded program} consists of all $N$ groundings, of
all rules.  Using more friendly indexes, we write the grounded program
as:
%
\begin{align}
  x_1 \cd & f_1(x_1, \ldots, x_N) \nonumber\\
          & \ldots \label{eq:grounded:pi} \\
  x_N \cd & f_N(x_1, \ldots, x_N) \nonumber
\end{align}
%
where each $f_i$ is a multivariate polynomial in the variables
$x_1, \ldots, x_N$.  We write $\bm f = (f_1, \ldots, f_N)$ for the
vector-valued function whose components are the $N$ provenance
polynomials, and define the semantics of the \datalogo program as its
least fixpoint, $\lfp(\bm f)$, when it exists,
% \hqn{with $\oplus$ and  $\otimes$ monotone, $\bm f$ is monotone and thus $\lfp(\bm f)$  always exists} 
where, as usual, we identify the tuple $\lfp(\bm f) \in \bm P^N$ with
an IDB instance $\lfp(\bm f) \in \inst(\tau,D_0,\bm P)$.  By
definition, $\lfp(\bm f)$ is equal to the least fixpoint of the ICO,
as defined in Sec.~\ref{subsec:ico}.


\subsection{Examples}

\label{subsec:datalogo:examples}

We illustrate \datalogo with two examples.  When the POPS $\bm P$ is a
naturally ordered semiring, then we will use the following {\em
  indicator function} $[C]_0^{1}$, which maps a Boolean condition $C$
to either $0 \in \bm P$ or $1 \in \bm P$, depending on whether $C$ is
false or true.  We write the indicator function simply as $[C]$, when
the values $0,1$ are clear from the context.  An indicator function
can be desugared by replacing
$\setof{[C] \otimes P_1 \otimes \cdots \otimes P_k}{\Phi}$ with
$\setof{P_1 \otimes \cdots \otimes P_k}{\Phi \wedge C}$.  When $\bm P$
is not naturally ordered, then we will not use indicator functions,
see Example~\ref{ex:conditional:sum:product}.



\begin{figure}
    \begin{subfigure}[b]{0.45\textwidth}
        \centering
        \begin{tikzpicture}[scale = 0.9, every node/.style={transform shape}]
            \node [draw, circle] at (0,0) (a) {$a$};
            \node [draw, circle] at (2,0) (b) {$b$};
            \node [draw, circle] at (4,0) (c) {$c$};
            \node [draw, circle] at (6,0) (d) {$d$};
            \draw [bend left,-Latex] (a) to node [auto, swap] {1} (b);
            \draw [bend left,-Latex] (b) to node [auto] {2} (a);
            \draw [bend right,-Latex] (b) to node [auto, swap] {3} (c);
            \draw [bend right,-Latex] (c) to node [auto] {4} (d);
            \draw [bend left=40,-Latex] (a) to node [auto, swap] {5} (c);
        \end{tikzpicture}
        \caption{}
    \end{subfigure}
    \begin{subfigure}[b]{0.45\textwidth}
        \centering
        \begin{tikzpicture}[scale = 0.9, every node/.style={transform shape}]
            \node [draw, circle] at (0,0) (a) {$a$};
            \node at (a) [below=.2, anchor = north] {$C=1$};
            \node [draw, circle] at (2,0) (b) {$b$};
            \node at (b) [above=.2, anchor = south] {$C=1$};
            \node [draw, circle] at (4,0) (c) {$c$};
            \node at (c) [above right=.25, anchor = south] {$C=1$};
            \node [draw, circle] at (6,0) (d) {$d$};
            \node at (d) [above=.2, anchor = south] {$C=10$};
            \draw [bend left,-Latex] (a) to (b);
            \draw [bend left,-Latex] (b) to (a);
            \draw [bend right,-Latex] (b) to (c);
            \draw [bend right,-Latex] (c) to (d);
            \draw [bend left=40,-Latex] (a) to (c);
        \end{tikzpicture}
        \caption{}
    \end{subfigure}
    \caption{A graph illustrating Example~\ref{ex:reachability:sssp} (a)
  and Example~\ref{ex:sum1:sum2} (b)}
  \label{fig:simple:graph}
\end{figure}


\begin{ex} \label{ex:reachability:sssp} Let the EDB and IDB
  vocabularies be $\sigma = \set{E}$ and $\tau = \set{L}$, where $E$
  is binary and $L$ is unary.  Consider the following \datalogo program:
  %
  \begin{align}
    L(X) \cd & [X=a] \oplus \bigoplus_Z \left(L(Z) \otimes E(Z,X)\right) \label{eq:reachability}
  \end{align}
  %
  where $a \in D$ is some constant in the domain.  We show three
  different interpretations of the program, over three different
  naturally ordered semirings.  First, we interpret it over the
  semiring of Booleans.  In this case, the program can be written in a
  more familiar notation:
  %
  \begin{align*}
    L(X) \cd & [X=a]_0^1 \vee \exists_Z \left(L(Z) \wedge E(Z,X)\right)
  \end{align*}
  %
  This is the reachability program, which computes the set of nodes
  $X$ reachable from the node $a$.  The indicator function $[X=a]_0^1$
  returns $0$ or $1$, depending on whether $X\neq a$ or $X=a$.

  Next, let's interpret it over $\trop^+$.  In that case, the
  indicator function $[X=a]_\infty^0$ returns $\infty$ when $X\neq a$,
  and returns $0$ when $X=a$.  The program becomes:
  %
  \begin{align*}
    L(X) \cd  & \min\left((\texttt{if } X=a\texttt{ then } 0 \texttt{ else } \infty),  \min_Z(L(Z) + E(Z,X))\right)
  \end{align*}
  %
  This program solves the Single-Source-Shortest-Path (SSSP) problem with source
  vertex $a$.
  Consider the graph in Fig.~\ref{fig:simple:graph}(a).  The active
  domain consists of the constants $a,b,c,d$, and the na\"ive evaluation
  algorithm converges after 5 steps, as shown here:
  \begin{align*}
      &
        \begin{array}{l|c|c|c|c|} \cline{2-5}
          &L(a)&L(b)&L(c)&L(d) \\ \cline{2-5}
          L^{(0)} & \infty & \infty & \infty & \infty  \\ \cline{2-5}
          L^{(1)} & 0 & \infty & \infty & \infty  \\ \cline{2-5}
          L^{(2)} & 0 & 1 & 5 & \infty  \\ \cline{2-5}
          L^{(3)} & 0 & 1 & 4 & 9  \\ \cline{2-5}
          L^{(4)} & 0 & 1 & 4 & 8  \\ \cline{2-5}
          L^{(5)} & 0 & 1 & 4 & 8  \\ \cline{2-5}
        \end{array}
  \end{align*}

  Third, let's interpret it over $\trop^+_p$, defined in
  Example~\ref{ex:trop:p}.  Assume for simplicity that $p=1$.  In that
  case the program computes, for each node $X$, the bag
  $\bag{l_1,l_2}$ of the lengths of the two shortest paths from $a$ to
  $X$.  The indicator function $[X=a]$ is equal to $\bag{0,\infty}$
  when $X=a$, and equal to $\bag{\infty,\infty}$ otherwise.  The
  reader may check that the program converges to:
  %
  \begin{align*}
    L(a) = &\bag{0,3} & L(b) = & \bag{1,4} &
    L(c) = &\bag{4,5} & L(d) = & \bag{8,9}
  \end{align*}

  Finally, we can interpret it over $\trop^+_{\leq \eta}$, the
  semiring in Example~\ref{ex:trop:eta}.  In that case the program
  computes, for each $X$, the set of all possible lengths of paths
  from $a$ to $X$ that are no longer than the shortest path plus
  $\eta$.
\end{ex}



\begin{ex} \label{ex:sum1:sum2} A classic problem that requires the
  interleaving of recursion and aggregation is the bill-of-material
  (see, e.g., \cite{DBLP:conf/amw/ZanioloYIDSC18}), where we are asked
  to compute, for each part $X$, the total cost of $X$, of all
  sub-parts of $X$, all sub-sub-parts of $X$, etc.  The EDB and IDB
  schemas are $\sigma_\B = \set{E}$, $\sigma = \set{C}$,
  $\tau=\set{T}$.  The relation $E(X,Y)$ is a standard, Boolean
  relation, representing the fact hat ``$X$ has a subpart $Y$''; $C(X)$
  is an $\N$-relation or an $\R_\bot$-relation (to be discussed
  shortly) representing the cost of $X$; and $T(X)$ is the {\em total
    cost} of $X$, that includes the cost of all its (sub-)subparts.
  The \datalogo program is:
  %
  \begin{align*}
    T(X) \cd & C(X) + \sum_Y \setof{T(Y)}{E(X,Y)}
  \end{align*}
  %
  When the graph defined by $E$ is a tree then the program computes
  correctly the bill-of-material.  We are interested, however, in what
  happens when the graph encoded by $E$ has cycles, as illustrate with
  Fig.~\ref{fig:simple:graph}(b).  The grounded program
  is:\footnote{Strictly speaking, we should have introduced POPS
    variables, $x_{T(a)}, x_{T(b)}, \ldots$, but, to reduce clutter,
    we show here directly the grounded atoms instead of their
    corresponding POPS variable.}
  %
  \begin{align*}
    T(a) \cd & C(a) + T(b) + T(c) \\
    T(b) \cd & C(b) + T(a) + T(c) \\
    T(c) \cd & C(c) + T(d) \\
    T(d) \cd & C(d)
  \end{align*}
  %
  We consider two choices for the POPS.  First, the naturally ordered
  semiring $(\N, +, *, 0, 1)$. Here the program diverges, since the
  na\"ive algorithm will compute ever increasing values for $T(a)$ and
  $T(b)$, which are on a cycle.  Second, consider the lifted reals
  $\R_\bot = (\R \cup \set{\bot},+,*,0,1,\sqsubseteq)$.  Now the
  program converges in 3 steps, as can be seen below:
%
  \begin{align*}
    &
      \begin{array}{l|c|c|c|c|} \cline{2-5}
        &T(a)&T(b)&T(c)&T(d) \\ \cline{2-5}
        T_0 & \bot & \bot & \bot & \bot  \\ \cline{2-5}
        T_1 & \bot & \bot & \bot & 10  \\ \cline{2-5}
        T_2 & \bot & \bot & 11 & 10  \\ \cline{2-5}
        T_3 & \bot & \bot & 11 & 10  \\ \cline{2-5}
        \end{array}
  \end{align*}
\end{ex}


\subsection{Extensions}

\label{subsec:extensions:datalogo}

We discuss here several extensions of \datalogo that we believe are
needed in a practical implementation.

{\bf Case Statements} Sum-products can be extended w.l.o.g. to include
case statements of the form:
  %
\begin{align*}
  T(x_1, \ldots, x_k) &\cd \texttt{case } C_1: E_1; \ \ \ C_2: E_2;\cdots; [\texttt{ else } E_n]
\end{align*}
%
where $C_1, C_2, \ldots$ are conditions and $E_1, E_2, \ldots$ are
sum-product expressions.  This can be desugared to a sum-sum-product:
%
\begin{align*}
  T(x_1, \ldots, x_k) &\cd \setof{E_1}{C_1} \oplus \setof{E_2}{\neg C_1 \wedge C_2} \oplus\cdots \oplus \setof{E_n}{\neg C_1 \wedge \neg C_2 \cdots}
\end{align*}
%
and therefore the least fixpoint semantics and our convergence results
in Sec.~\ref{sec:complexity} continue to hold.
%
For example, we may compute the prefix-sum of a vector $V$ of length
100 as follows:
%
\begin{align*}
  W(i) &\cd \texttt{case } i=0: V(0);\ \ \ \ i<100: W(i-1) + V(i);
\end{align*}
%

{\bf Multiple Value Spaces} Our discussion so far assumed that all
rules in a \datalogo program are over a single POPS.  In practice one
often wants to perform computations over multiple POPS.  In that case
we need to have some predefined functions mapping between various
POPS; if these are monotone, then the least fixpoint semantics still
applies, otherwise the program needs to be {\em stratified}.  We
illustrate with an example, which uses two POPS: $\R_+$ and $\B$.

\begin{ex} We illustrate the {\em company control} example
  from~\cite[Example 3.2]{DBLP:conf/pods/RossS92}.
  $S(X,Y)=n \in \R_+$ represents the fact that company $X$ owns a
  proportion of $n$ shares in company $Y$.  We want to compute the
  predicate $C(X,Y)$, representing the fact that the company $X$ {\em
    controls} company $Y$, where control is defined as follows: $X$
  controls $Y$ if the sum of shares it owns in $Y$ plus the sum of
  shares in $Y$ owned by companies controlled by $X$ is $>0.5$.  The
  program is adapted directly from~\cite{DBLP:conf/pods/RossS92}:
  %
  \begin{align*}
    CV(X,Z,Y) \cd & [X=Z]*S(X,Y) + [C(X,Z)]*S(Z,Y) \\
    T(X,Y) \cd & \sum_Z \setof{CV(X,Z,Y)}{\text{Company}(Z)} \\
    C(X,Y) \cd & [T(X,Y) > 0.5]
  \end{align*}
  %
  The value of $CV(X,Z,Y)$ is the fraction of shares that $X$ owns in
  $Y$, through its control of company $Z$; when $X=Z$ then this
  fraction includes $S(X,Y)$.  The value of $T(X,Y)$ is the total
  amount of shares that $X$ owns in $Y$.  The last rule checks whether
  this total is $>0.5$: in that case, $X$ controls $Y$.

  The EDB and IDB vocabularies are $\sigma = \set{S}$,
  $\sigma_\B = \set{\text{Company}}$,
  $\tau = \set{CV, T}, \tau_\B = \set{C}$.  The IDBs $CV, T$ are
  $\R_+$-relations, $C$ is a standard $\B$-relation.  The mapping
  between the two POPS is achieved by the indicator function
  $[\Phi] \in \R_+$, which returns 0 when the predicate $\Phi$ is
  false, and 1 otherwise.  All rules are monotone, w.r.t. to the
  natural orders on $\R_+$ and $\B$, and, thus, the least-fixpoint
  semantics continues to apply to this program. But the results in
  Sec.~\ref{sec:complexity} apply only to fixpoints of polynomials,
  while the grounding of our program is no longer a polynomial.
\end{ex}

% {\bf Stratification} When using non-monotone functions between
% different POPS, one needs to stratify the \datalogo, as is custom for
% datalog with negation.

{\bf Interpreted functions over the key-space} A practical language
needs to allow interpreted functions over the key space, i.e. the
domain $D$, as illustrated by this simple example:
  %
\begin{align*}
  \texttt{Shipping}(cid,\texttt{date}+1) \cd & \texttt{Order}(cid,\texttt{date})
\end{align*}
  %
Here $\texttt{date}+1$ is an interpreted function applied to
$\texttt{date}$.  Interpreted functions over $D$ may cause the active
domain to grow indefinitely, leading to divergence; our results in
Sec.~\ref{sec:complexity} apply only when the active domain is fixed,
enabling us to define the grounding~\eqref{eq:grounded:pi} of the
\datalogo program.

%   {\bf Cast Operator} Each \datalogo rule is over a single POPS $\bm S$.
%   If we want to compute a program over multiple POPS then we need some
%   mechanism to compute a rule over two or more POPS.  The simplest
%   way is to combine Boolean predicates with $\bm S$-relations over
%   some other POPS, using an indicator function
%   $[-] : \B \rightarrow \bm S$, defined as follows:
% %
%   \begin{align*}
%     [0] \defeq & \bot_{\bm S} &
%     [1] \defeq & 1_{\bm S}
%   \end{align*}
% %
%   We call $[-]$ a {\em cast} operator.  When the cast operator is
%   applied only to Boolean EDB predicates, then it can be computed
%   during grounding, in other words, the result of grounding a rule
%   continues to be a multivariate polynomial over the POPS $\bm S$.
%   However, if the condition is applied to Boolean IDBs, then the ICO
%   is still a monotone operator, since the cast operator above is
%   monotone, but the grounding is no longer a polynomial, and the
%   results in the next section may no longer apply.

%   {\bf Summation with Explicit Range} We allow an explicit range in
%   the summation of a monomial.  This is necessary when
%   $\bot_{\bm S} \neq 0$, because in that case the indicator function
%   cannot be used to restrict the range of the summation.  More
%   precisely, we extend the definition of a sum-product expression in
%   Def.~\ref{def:sum:product} to:
% %
%   \begin{align*}
%      T(x_1, \ldots, x_k) &\cd \bigoplus_{x_{k+1}, \ldots,x_p \in D} \setof{A_1 \otimes  \cdots \otimes A_m}{\text{Cond}}
%   \end{align*}
%   %
%   where $\text{Cond}$ is a condition over the variables
%   $x_{k+1}, \ldots, x_p$, restricting their range.  This extension
%   affects only how we compute the grounding of a rule: we simply
%   restrict the summation $f(u_1)+f(u_2)+\cdots+f(u_{|D|})$ to include
%   only terms that satisfy the condition.  The result of grounding is
%   still a multivariate polynomial over the POPS $\bm S$.

{\bf Keys to Values} Finally, a useful extension is to allow key
values to be used as POPS values, when the types are right.  For
example, if $\texttt{Length}(X,Y,C)$ is Boolean relation, where a
tuple $(X,Y,C)$ represents the fact that there exists a path of length
$C$ from $X$ to $Y$, then the we can compute the length of the
shortest path as the following rule of the tropical semiring
$\trop^+$:
%
  \begin{align*}
    \texttt{ShortestLength}(X,Y) &\cd \min_C \left([\texttt{Length}(X,Y,C)]_\infty^0 + C\right)
  \end{align*}
%
  The key variable $C$ became an atom over the tropical semiring.

\section{Convergence of \datalogo}
\label{sec:convergence}

At its essence, a \datalogo program consists of solving a fixpoint
equation in a semiring, which is a problem that was studied in a variety
of areas, like automata theory, program analysis, and many
others~\cite{MR1470001,DBLP:conf/popl/CousotC77,MR1728440,MR1059930,
  DBLP:conf/lics/HopkinsK99, DBLP:journals/tcs/Lehmann77,
  semiring_book,MR609751}.  The existence of the fixpoint is usually
ensured by requiring the semiring to be $\omega$-continuous. For
example, Green et al.~\cite{DBLP:conf/pods/GreenKT07} studied the
provenance of Datalog on $K$-relations, while Esparza et
al.~\cite{DBLP:journals/jacm/EsparzaKL10} studied dataflow equations,
in both cases requiring the semiring to be $\omega$-continuous.  This
guarantees that the least fixpoint exists, even if the na\"ive algorithm
diverges.
We do not use $\omega$-continuity in this paper,
 and will not define it formally.
Instead, we are interested in the cases 
 where the na\"ive algorithm converges to the least fixpoint.

Computing the least fixpoint of \datalogo using the na\"ive algorithm
 is quite similar to Datalog:
initialize all IDBs to $\bot$,
then repeatedly apply all rules of the \datalogo program, obtaining an
increasing chain of IDB instances,
$J^{(0)} \sqsubseteq J^{(1)} \sqsubseteq J^{(2)} \sqsubseteq \cdots$
When $J^{(t)} = J^{(t+1)}$, then the algorithm stops and returns
$J^{(t)}$; in that case we say that the \datalogo program converges in
$t$ steps, or we just say that it converges; otherwise we say that it
diverges.  Traditional Datalog always converges, but this is no longer
the case for \datalogo programs.  There are five possibilities,
depending on the choice of the POPS $\bm P$:
%
\begin{enumerate}[label=(\roman*)]
\item \label{item:converge:1} For some \datalogo programs, $\bigvee_t J^{(t)}$ is not the least fixpoint.
\item \label{item:converge:2} Every \datalogo program has the least fixpoint $\bigvee_t J^{(t)}$, but may not necessarily converge.
\item \label{item:converge:3} Every \datalogo program converges.
\item \label{item:converge:4} Every \datalogo program converges in a
  number of steps that depends only on $|\adom(I)|$.
\item \label{item:converge:5} Every \datalogo program converges in a
  number of steps that is polynomial in $|\adom(I)|$.
\end{enumerate}
%
In this paper, we will only consider
data-complexity~\cite{DBLP:conf/stoc/Vardi82}, where the \datalogo
program is assumed to be fixed, and the input consists only of the EDB
instance $I$.

We study algebraic properties of the POPS $\bm P$ that ensure that we
are in one of the cases~\ref{item:converge:3}-\ref{item:converge:5};
we do not address cases~\ref{item:converge:1}-\ref{item:converge:2} in
this paper.  We give next a necessary and sufficient condition for
each of the cases~\ref{item:converge:3} and~\ref{item:converge:4}, and
give a sufficient condition for case~\ref{item:converge:5}.  
For any POPS $\bm P$, the set
$\bm P \oplus \bot \defeq \setof{u\oplus \bot}{u \in P}$ is a
semiring (Proposition~\ref{prop:s:plus:bot}); our characterization is based entirely on a certain
property, called {\em stability}, of the semiring $\bm P \oplus \bot$,
which we describe here.

Given a semiring $\bm S$ and $u \in S$, denote by
$u^{(p)} := 1 \oplus u \oplus u^2 \oplus \cdots \oplus u^{p}$, where
$u^{i} := u \otimes u \otimes \cdots \otimes u$ ($i$ times).  We say
that $u$ is {\em $p$-stable} if $u^{(p)}=u^{(p+1)}$; we say that the
semiring $\bm S$ is {\em $p$-stable} if every element $u \in S$ is $p$-stable, and
we say that $\bm S$ is {\em stable} if every element $u$ is stable for some
$p$ that may depend on $u$.
A \datalogo program is {\em linear} if every rule has at most one IDB predicate in the body.
We prove:

\begin{thm} \label{th:main:intro} Given a POPS $\bm P$, the following hold.
  \begin{itemize}
  \item Every \datalogo program converges iff the semiring $\bm P\oplus \bot$ is stable.
  \item Every program converges in a number of steps that depends only
    on $|\adom(I)|$ iff $\bm P \oplus \bot$ is $p$-stable for some
    $p$.  More precisely, every \datalogo program converges in
    $\sum_{i=1}^{N}(p+2)^i$ steps, where $N$ is the number of ground
    tuples consisting of IDB predicates and constants from $\adom(I)$.
    Furthermore, if the program is linear, then it converges in $\sum_{i=1}^N(p+1)^i$ steps.
  \item If $\bm P\oplus \bot$ is $0$-stable, then every \datalogo
    program converges in $N$ steps; in particular, the program runs in
    polynomial time in the size of the input database.
  \end{itemize}
\end{thm}

In a nutshell, the theorem says that convergence of \datalogo is
intimately related to the notion of stability.  The proof, provided in
Sec.~\ref{sec:complexity}, consists of an analysis of the infinite
powerseries resulting from unfolding the fixpoint definition; for
the proof of the first item we also use Parikh's
theorem~\cite{MR209093}.  As mentioned earlier, most prior work on
fixpoint equations assumes an $\omega$-continuous semiring; when
convergence is desired, one usually offers the Ascending Chain
Condition, ACC (see Sec.~\ref{sec:lfp}) as a sufficient condition for
convergence.  Our theorem implies that ACC is only a sufficient, but
not a necessary condition for convergence, for example $\trop^+$ is
$0$-stable, and therefore every \datalogo program converges on
$\trop^+$, yet it does not satisfy the ACC condition.  A somewhat
related result is proven by Luttenberger and
Schlund~\cite{DBLP:journals/iandc/LuttenbergerS16} who showed that, if
$1$ is $p$-stable, then Newton's method requires at most
$N + \log\log p$ iterations.  As mentioned earlier, each step of
Newton's method requires the computation of another least fixpoint,
hence that result does not inform us on the convergence of the na\"ive
algorithm.

\section{Semi-na\"ive Evaluation for \datalogo}
\label{sec:semi-naive}

Next, we introduce an extension of the semi-na\"ive evaluation
algorithm to \datalogo.  It is known that the na\"ive evaluation
algorithm is inefficient in practice, because at each iteration it
repeats all the computations that it has done at the previous
iterations.  Most Datalog systems implement an improvement called the
{\em semi-na\"ive} evaluation, which keeps track of the delta between
the successive states of the IDBs and applies the Datalog rules as a
function of these deltas to obtain the new iteration's deltas.
Semi-na\"ive evaluation is one of the major optimization techniques
for evaluating Datalog, however, it is defined only for programs that
are monotone under set inclusion, and the systems that implement it
enforce monotonicity, preventing the use of aggregation in
recursion. Our second result consists of showing how to adapt the
semi-na\"ive algorithm to \datalogo, under certain restrictions of the
POPS $\bm P$, thus, enabling the semi-na\"ive algorithm to be applied
to programs with aggregation in recursion.
