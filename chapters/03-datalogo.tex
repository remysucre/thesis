\chapter{The \datalogo Language}
\label{chap:datalogo}

\remy{Define the semantics for \datalogo, 
 state the convergence theorems, 
 and give examples for each case.
 Then describe the semi-na\"ive algorithm.}

For fifty years, the relational data model has been the main choice for
representing, modeling, and processing data.  Its main query
language, SQL, is found today in a wide range of applications and
devices, from smart phones, to database servers, to distributed
cloud-based clusters.  The reason for its success is the {\em data
  independence principle}, which separates the declarative model from
the physical implementation~\cite{DBLP:journals/cacm/Codd70}, and
enables advanced implementation techniques, such as cost-based
optimizations, indices, materialized views, incremental view
maintenance, parallel evaluation, and many others, while keeping the
same simple, declarative interface to the data unchanged.

But scientists today often need to perform tasks that require
iteration over the data.
Gradient descent, clustering, page-rank, network centrality, inference
in knowledge graphs are some examples of common tasks in data science
that require iteration.  While SQL has introduced recursion since 1999
(through Common Table Expressions, CTE), it has many cumbersome
limitations and is little used in practice~\cite{frankmcsherry-2022}.

The need to support recursion in a declarative language led to the
development of Datalog in the mid 80s~\cite{DBLP:conf/pods/Vianu21}.
Datalog adds recursion to the relational query language, yet enjoys several elegant
properties: it has a simple, declarative semantics; its na\"ive
bottom-up evaluation algorithm always terminates; and it admits a few
powerful optimizations, such as semi-na\"ive evaluation and magic set
rewriting.  Datalog has been extensively studied in the literature;
see~\cite{DBLP:journals/ftdb/GreenHLZ13} for a survey
and~\cite{DBLP:books/mc/18/MaierTKW18,DBLP:conf/pods/Vianu21} for historical notes.

However, Datalog is not the answer to modern needs, because it only
supports monotone queries over sets.  Most tasks in data science today
require the interleaving of recursion and aggregate computation.
Aggregates are not monotone under set inclusion, and therefore they
are not supported by the framework of pure Datalog.  Neither SQL'99
nor popular open-source Datalog systems like
Souffl\'e~\cite{DBLP:conf/cav/JordanSS16} allow recursive queries to
have aggregates.  While several proposals have been made to extend
Datalog with
aggregation~\cite{DBLP:conf/pods/GangulyGZ91,DBLP:conf/pods/RossS92,DBLP:journals/jcss/GangulyGZ95,DBLP:journals/vldb/MazuranSZ13,DBLP:conf/icde/ShkapskyYZ15,DBLP:conf/sigmod/ShkapskyYICCZ16,DBLP:conf/amw/ZanioloYDI16,DBLP:journals/tplp/ZanioloYDSCI17,DBLP:conf/amw/ZanioloYIDSC18,DBLP:journals/tplp/CondieDISYZ18,DBLP:conf/sigmod/0001WMSYDZ19,DBLP:journals/corr/abs-1910-08888,DBLP:journals/corr/abs-1909-08249,DBLP:journals/debu/ZanioloD0LL021},
these extensions are at odds with the elegant properties of Datalog
and have not been adopted by either Datalog systems or SQL engines.

In this paper we propose a foundation for a query language that
supports both recursion and aggregation.  Our proposal is based on the
concept of $K$-relations, introduced in a seminal
paper by Green, Karvounarakis, and Tannen~\cite{DBLP:conf/pods/GreenKT07}.
In a $K$-relation, tuples are
mapped to a fixed semiring. Standard relations (sets) are
$\B$-relations where tuples are mapped to the Boolean semiring $\B$,
relations with duplicates (bags) are $\N$-relations, sparse tensors
are $\R$-relations, and so on.  Queries over $K$-relations are the
familiar relational queries, where the operations $\wedge, \vee$ are
replaced by the operations $\otimes, \oplus$ in the semiring;
importantly, an existential quantifier $\exists$ becomes an
$\oplus$-aggregate operator.
$K$-relations are a very powerful abstraction, because they open up
the possibility of adapting query processing and optimization
techniques to other domains~\cite{DBLP:conf/pods/KhamisNR16}.

Our first contribution is to introduce an extension of Datalog to
$K$-relations.  We call the language \datalogo 
 (pronounced ``Datalog-Oh''),
 where the superscript
$\circ$ represents a (semi)-ring. \datalogo has a declarative semantics
based on the least fixpoint, and supports both recursion and
aggregates.  We illustrate throughout this paper its utility through
several examples that are typical for recursive data processing.  In
order to define the least fixpoint semantics of \datalogo, the semiring
needs to be partially ordered.  For this purpose, we introduce an
algebraic structure called a {\em Partially Ordered Pre-Semiring (POPS)\/},
which generalizes the more familiar naturally ordered semirings.  This
generalization is necessary for some applications.  For example, the
bill-of-material program (Example~\ref{ex:sum1:sum2}) is naturally
expressed over the lifted reals, $\R_\bot$, which is a POPS that is
not naturally ordered.

Like Datalog, \datalogo can be evaluated using the {\em na\"ive algorithm},
by repeatedly applying all rules of the program, until there is no
more change.  However, unlike Datalog, a \datalogo program may diverge.
Our second contribution consists of a full characterization of the
POPS that guarantee that every \datalogo program terminates.  More
precisely, we show that termination is guaranteed iff the POPS enjoys
a certain algebraic property called {\em
  stability}~\cite{semiring_book}.  The result is based on an analysis
of the fixpoint of a vector-valued polynomial function over a semiring, which is of
independent interest.  With some abuse, we will say in this paper that
a \datalogo program {\em converges}, if the na\"ive algorithm terminates
in a finite number of steps; we do not consider ``convergence in the
limit'', for example in an $\omega$-continuous
semirings~\cite{DBLP:conf/pods/GreenKT07,DBLP:journals/jacm/EsparzaKL10}.

Finally, we describe how the {\em semi-na\"ive algorithm} can be
extended to \datalogo, under certain restrictions on the POPS.  This
should be viewed as an illustration of the potential for applying
advanced optimizations to \datalogo: in a companion
paper~\cite{DBLP:conf/sigmod/WangK0PS22}, we introduced a simple, yet
powerful optimization technique for \datalogo, and showed, among other
things, that magic set rewriting can be obtained using several
applications of that rule.

The remainder of this Chapter is organized as follows. 
We define POPS in Sec.~\ref{sec:pops} and give several examples.
In Sec.~\ref{sec:lfp} we consider the least fixpoint of monotone
functions over posets, and prove an upper bound on the number of
iterations needed to compute the least fixpoint.  We define \datalogo
formally in Sec.~\ref{sec:datalogo}, and give several examples.
The convergence results described in Theorem~\ref{th:main:intro} are
stated formally and proven in Sec.~\ref{sec:complexity}.
Sec.~\ref{sec:semi:naive} presents a generalization of semi-na\"ive
evaluation to \datalogo.  We discuss how \datalogo can express Datalog
queries with negation using 3-valued logic in
Sec.~\ref{sec:fitting}.  Finally, we conclude in
Sec.~\ref{sec:conclusions}.

\section{Partially Ordered Pre-Semirings (POPS)}
\label{sec:pops}

\section{\datalogo}
\label{sec:datalogo}

\section{Convergence of \datalogo}
\label{sec:convergence}

At its essence, a \datalogo program consists of solving a fixpoint
equation in a semiring, which is a problem that was studied in a variety
of areas, like automata theory, program analysis, and many
others~\cite{MR1470001,DBLP:conf/popl/CousotC77,MR1728440,MR1059930,
  DBLP:conf/lics/HopkinsK99, DBLP:journals/tcs/Lehmann77,
  semiring_book,MR609751}.  The existence of the fixpoint is usually
ensured by requiring the semiring to be $\omega$-continuous. For
example, Green et al.~\cite{DBLP:conf/pods/GreenKT07} studied the
provenance of Datalog on $K$-relations, while Esparza et
al.~\cite{DBLP:journals/jacm/EsparzaKL10} studied dataflow equations,
in both cases requiring the semiring to be $\omega$-continuous.  This
guarantees that the least fixpoint exists, even if the na\"ive algorithm
diverges.
We do not use $\omega$-continuity in this paper,
 and will not define it formally.
Instead, we are interested in the cases 
 where the na\"ive algorithm converges to the least fixpoint.

Computing the least fixpoint of \datalogo using the na\"ive algorithm
 is quite similar to Datalog:
initialize all IDBs to $\bot$,
then repeatedly apply all rules of the \datalogo program, obtaining an
increasing chain of IDB instances,
$J^{(0)} \sqsubseteq J^{(1)} \sqsubseteq J^{(2)} \sqsubseteq \cdots$
When $J^{(t)} = J^{(t+1)}$, then the algorithm stops and returns
$J^{(t)}$; in that case we say that the \datalogo program converges in
$t$ steps, or we just say that it converges; otherwise we say that it
diverges.  Traditional Datalog always converges, but this is no longer
the case for \datalogo programs.  There are five possibilities,
depending on the choice of the POPS $\bm P$:
%
\begin{enumerate}[label=(\roman*)]
\item \label{item:converge:1} For some \datalogo programs, $\bigvee_t J^{(t)}$ is not the least fixpoint.
\item \label{item:converge:2} Every \datalogo program has the least fixpoint $\bigvee_t J^{(t)}$, but may not necessarily converge.
\item \label{item:converge:3} Every \datalogo program converges.
\item \label{item:converge:4} Every \datalogo program converges in a
  number of steps that depends only on $|\adom(I)|$.
\item \label{item:converge:5} Every \datalogo program converges in a
  number of steps that is polynomial in $|\adom(I)|$.
\end{enumerate}
%
In this paper, we will only consider
data-complexity~\cite{DBLP:conf/stoc/Vardi82}, where the \datalogo
program is assumed to be fixed, and the input consists only of the EDB
instance $I$.

We study algebraic properties of the POPS $\bm P$ that ensure that we
are in one of the cases~\ref{item:converge:3}-\ref{item:converge:5};
we do not address cases~\ref{item:converge:1}-\ref{item:converge:2} in
this paper.  We give next a necessary and sufficient condition for
each of the cases~\ref{item:converge:3} and~\ref{item:converge:4}, and
give a sufficient condition for case~\ref{item:converge:5}.  
For any POPS $\bm P$, the set
$\bm P \oplus \bot \defeq \setof{u\oplus \bot}{u \in P}$ is a
semiring (Proposition~\ref{prop:s:plus:bot}); our characterization is based entirely on a certain
property, called {\em stability}, of the semiring $\bm P \oplus \bot$,
which we describe here.

Given a semiring $\bm S$ and $u \in S$, denote by
$u^{(p)} := 1 \oplus u \oplus u^2 \oplus \cdots \oplus u^{p}$, where
$u^{i} := u \otimes u \otimes \cdots \otimes u$ ($i$ times).  We say
that $u$ is {\em $p$-stable} if $u^{(p)}=u^{(p+1)}$; we say that the
semiring $\bm S$ is {\em $p$-stable} if every element $u \in S$ is $p$-stable, and
we say that $\bm S$ is {\em stable} if every element $u$ is stable for some
$p$ that may depend on $u$.
A \datalogo program is {\em linear} if every rule has at most one IDB predicate in the body.
We prove:

\begin{thm} \label{th:main:intro} Given a POPS $\bm P$, the following hold.
  \begin{itemize}
  \item Every \datalogo program converges iff the semiring $\bm P\oplus \bot$ is stable.
  \item Every program converges in a number of steps that depends only
    on $|\adom(I)|$ iff $\bm P \oplus \bot$ is $p$-stable for some
    $p$.  More precisely, every \datalogo program converges in
    $\sum_{i=1}^{N}(p+2)^i$ steps, where $N$ is the number of ground
    tuples consisting of IDB predicates and constants from $\adom(I)$.
    Furthermore, if the program is linear, then it converges in $\sum_{i=1}^N(p+1)^i$ steps.
  \item If $\bm P\oplus \bot$ is $0$-stable, then every \datalogo
    program converges in $N$ steps; in particular, the program runs in
    polynomial time in the size of the input database.
  \end{itemize}
\end{thm}

In a nutshell, the theorem says that convergence of \datalogo is
intimately related to the notion of stability.  The proof, provided in
Sec.~\ref{sec:complexity}, consists of an analysis of the infinite
powerseries resulting from unfolding the fixpoint definition; for
the proof of the first item we also use Parikh's
theorem~\cite{MR209093}.  As mentioned earlier, most prior work on
fixpoint equations assumes an $\omega$-continuous semiring; when
convergence is desired, one usually offers the Ascending Chain
Condition, ACC (see Sec.~\ref{sec:lfp}) as a sufficient condition for
convergence.  Our theorem implies that ACC is only a sufficient, but
not a necessary condition for convergence, for example $\trop^+$ is
$0$-stable, and therefore every \datalogo program converges on
$\trop^+$, yet it does not satisfy the ACC condition.  A somewhat
related result is proven by Luttenberger and
Schlund~\cite{DBLP:journals/iandc/LuttenbergerS16} who showed that, if
$1$ is $p$-stable, then Newton's method requires at most
$N + \log\log p$ iterations.  As mentioned earlier, each step of
Newton's method requires the computation of another least fixpoint,
hence that result does not inform us on the convergence of the na\"ive
algorithm.

\section{Semi-na\"ive Evaluation for \datalogo}
\label{sec:semi-naive}

Next, we introduce an extension of the semi-na\"ive evaluation
algorithm to \datalogo.  It is known that the na\"ive evaluation
algorithm is inefficient in practice, because at each iteration it
repeats all the computations that it has done at the previous
iterations.  Most Datalog systems implement an improvement called the
{\em semi-na\"ive} evaluation, which keeps track of the delta between
the successive states of the IDBs and applies the Datalog rules as a
function of these deltas to obtain the new iteration's deltas.
Semi-na\"ive evaluation is one of the major optimization techniques
for evaluating Datalog, however, it is defined only for programs that
are monotone under set inclusion, and the systems that implement it
enforce monotonicity, preventing the use of aggregation in
recursion. Our second result consists of showing how to adapt the
semi-na\"ive algorithm to \datalogo, under certain restrictions of the
POPS $\bm P$, thus, enabling the semi-na\"ive algorithm to be applied
to programs with aggregation in recursion.
